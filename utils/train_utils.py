# è¯¥è„šæœ¬ä¸ºKerasé£æ ¼çš„PyTorchè®­ç»ƒæ¡†æ¶
# å¯¼å…¥PyTorchæ ¸å¿ƒåº“ï¼Œç”¨äºæ·±åº¦å­¦ä¹ æ¨¡å‹æ„å»ºå’Œè®­ç»ƒ
import torch

# å¯¼å…¥ç³»ç»Ÿæ¨¡å—å’Œæ—¥æœŸæ—¶é—´æ¨¡å—
# sysï¼šç”¨äºç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼Œå¦‚æ ‡å‡†è¾“å‡ºé‡å®šå‘
# datetimeï¼šç”¨äºå¤„ç†æ—¥æœŸå’Œæ—¶é—´ï¼Œè®°å½•è®­ç»ƒæ—¶é—´ç­‰
import sys,datetime

# å¯¼å…¥tqdmåº“ï¼Œç”¨äºåœ¨å¾ªç¯ä¸­æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
from tqdm import tqdm 

# å¯¼å…¥deepcopyå‡½æ•°ï¼Œç”¨äºåˆ›å»ºå¯¹è±¡çš„æ·±åº¦æ‹·è´ï¼Œé¿å…å¯¹è±¡å¼•ç”¨é—®é¢˜
from copy import deepcopy

# å¯¼å…¥NumPyåº“ï¼Œç”¨äºæ•°å€¼è®¡ç®—å’Œæ•°ç»„æ“ä½œ
import numpy as np

# å¯¼å…¥pandasåº“ï¼Œç”¨äºæ•°æ®å¤„ç†å’Œåˆ†æï¼Œç‰¹åˆ«æ˜¯DataFrameæ“ä½œ
import pandas as pd

# å†æ¬¡å¯¼å…¥torchï¼ˆä»£ç ä¸­é‡å¤å¯¼å…¥ï¼Œå®é™…å¯ä»¥åˆ é™¤è¿™è¡Œï¼‰
import torch

# å¯¼å…¥Acceleratorï¼Œç”¨äºæ”¯æŒå¤šGPU/TPUè®­ç»ƒå’Œæ··åˆç²¾åº¦è®­ç»ƒ
from accelerate import Accelerator


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ç”¨äºåœ¨æ§åˆ¶å°è¾“å‡ºå½©è‰²æ–‡æœ¬ï¼Œæå‡è®­ç»ƒè¿‡ç¨‹ä¸­ä¿¡æ¯çš„å¯è¯»æ€§
def colorful(obj,color="red", display_type="plain"):
    # å®šä¹‰é¢œè‰²ä»£ç å­—å…¸ï¼Œæ˜ å°„é¢œè‰²åç§°åˆ°ANSIè½¬ä¹‰åºåˆ—ä»£ç 
    color_dict = {"black":"30", "red":"31", "green":"32", "yellow":"33",
                    "blue":"34", "purple":"35","cyan":"36",  "white":"37"}
    # å®šä¹‰æ˜¾ç¤ºç±»å‹å­—å…¸ï¼Œæ˜ å°„æ˜¾ç¤ºæ•ˆæœåˆ°ANSIè½¬ä¹‰åºåˆ—ä»£ç 
    display_type_dict = {"plain":"0","highlight":"1","underline":"4",
                "shine":"5","inverse":"7","invisible":"8"}
    # å°†è¾“å…¥å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    s = str(obj)
    # æ ¹æ®æŒ‡å®šé¢œè‰²è·å–å¯¹åº”çš„ANSIä»£ç ï¼Œå¦‚æœé¢œè‰²ä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    color_code = color_dict.get(color,"")
    # æ ¹æ®æŒ‡å®šæ˜¾ç¤ºç±»å‹è·å–å¯¹åº”çš„ANSIä»£ç ï¼Œå¦‚æœç±»å‹ä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    display  = display_type_dict.get(display_type,"")
    # æ„é€ å®Œæ•´çš„ANSIè½¬ä¹‰åºåˆ—ï¼šå¼€å§‹æ ‡è®° + æ–‡æœ¬å†…å®¹ + ç»“æŸæ ‡è®°
    out = '\033[{};{}m'.format(display,color_code)+s+'\033[0m'
    # è¿”å›æ ¼å¼åŒ–åçš„å½©è‰²æ–‡æœ¬å­—ç¬¦ä¸²
    return out 


# å®šä¹‰StepRunnerç±»ï¼Œè´Ÿè´£å¤„ç†è®­ç»ƒæˆ–éªŒè¯è¿‡ç¨‹ä¸­çš„å•ä¸ªæ­¥éª¤ï¼ˆä¸€ä¸ªbatchçš„å¤„ç†ï¼‰
class StepRunner:
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®è®­ç»ƒæ­¥éª¤æ‰€éœ€çš„å„ç§ç»„ä»¶
    def __init__(self, net, loss_fn, accelerator, stage = "train", metrics_dict = None,
                 optimizer = None, lr_scheduler = None
                 ):
        # ä¿å­˜æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€è¯„ä¼°æŒ‡æ ‡å­—å…¸å’Œå½“å‰é˜¶æ®µï¼ˆè®­ç»ƒæˆ–éªŒè¯ï¼‰
        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage
        # ä¿å­˜ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler
        # ä¿å­˜Acceleratorå®ä¾‹ï¼Œç”¨äºå¤šè®¾å¤‡è®­ç»ƒ
        # è¿™æ˜¯huggingfaceçš„ä¸€ä¸ªåº“ï¼Œè‡ªåŠ¨é€‰æ‹©gpuè¿˜æ˜¯cpuï¼ˆå¦‚æœæœ‰å¤šä¸ªå¡ç”¨å¤šä¸ªå¡ï¼‰å¹¶å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
        self.accelerator = accelerator

    # å®šä¹‰__call__æ–¹æ³•ï¼Œä½¿ç±»å®ä¾‹å¯ä»¥åƒå‡½æ•°ä¸€æ ·è¢«è°ƒç”¨ï¼Œå¤„ç†å•ä¸ªbatchçš„æ•°æ®
    def __call__(self, batch):
        # ä»batchä¸­æå–ç‰¹å¾å’Œæ ‡ç­¾
        # featuresæ˜¯æ•´ä¸ªbatchæ•°æ®ï¼Œlabelsæ˜¯batch.yï¼ˆç›®æ ‡å€¼ï¼‰
        # .yæ˜¯PyTorch Geometricä¸­æ•°æ®å¯¹è±¡çš„å±æ€§ï¼Œè¿™ä¸ªæ¨¡å‹ä¸­è¡¨ç¤ºææ–™çš„ç›®æ ‡æ€§è´¨
        features,labels = batch,batch.y
        
        # å‰å‘ä¼ æ’­ï¼šå°†ç‰¹å¾è¾“å…¥æ¨¡å‹å¾—åˆ°é¢„æµ‹ç»“æœ
        preds = self.net(features)
        
        # ä¿®å¤é¢„æµ‹å€¼å’Œæ ‡ç­¾ä¹‹é—´çš„ç»´åº¦ä¸åŒ¹é…é—®é¢˜
        # è¿™æ˜¯å¤„ç†ä¸åŒæ•°æ®æ ¼å¼æ—¶å¸¸è§çš„é—®é¢˜
        # ç–‘é—®ï¼šå¦‚æœä¸æ˜¯è¿™ä¸¤ç§æƒ…å†µæ€ä¹ˆåŠï¼Ÿéš¾é“è¾“å‡ºå±‚æŒ‡å®šè¾“å‡ºå½¢çŠ¶äº†å—
        if preds.dim() != labels.dim():
            # å¦‚æœé¢„æµ‹å€¼æ˜¯1ç»´è€Œæ ‡ç­¾æ˜¯2ç»´ï¼Œåˆ™å‹ç¼©æ ‡ç­¾çš„æœ€åä¸€ä¸ªç»´åº¦
            if preds.dim() == 1 and labels.dim() == 2:
                labels = labels.squeeze(-1)
            # å¦‚æœé¢„æµ‹å€¼æ˜¯2ç»´è€Œæ ‡ç­¾æ˜¯1ç»´ï¼Œåˆ™å‹ç¼©é¢„æµ‹å€¼çš„æœ€åä¸€ä¸ªç»´åº¦
            elif preds.dim() == 2 and labels.dim() == 1:
                preds = preds.squeeze(-1)
        
        # è®¡ç®—æŸå¤±å‡½æ•°ï¼šæ¯”è¾ƒé¢„æµ‹å€¼å’ŒçœŸå®æ ‡ç­¾
        # è¿™ä¸ªå‡½æ•°å¯èƒ½åœ¨# - main.py ä¸­çš„ build_keras å‡½æ•°
        # - utils/model_utils.py
        # - utils/loss_utils.py  å®šä¹‰äº†æŸå¤±å‡½æ•°
        loss = self.loss_fn(preds,labels)

        # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°ï¼ˆä»…åœ¨è®­ç»ƒé˜¶æ®µæ‰§è¡Œï¼‰
        if self.optimizer is not None and self.stage=="train":
            # ä½¿ç”¨acceleratorè¿›è¡Œåå‘ä¼ æ’­ï¼Œè‡ªåŠ¨å¤„ç†å¤šè®¾å¤‡æƒ…å†µ
            self.accelerator.backward(loss)
            # æ‰§è¡Œä¼˜åŒ–å™¨æ­¥éª¤ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°
            self.optimizer.step()
            # æ¸…é›¶æ¢¯åº¦ï¼Œä¸ºä¸‹ä¸€æ¬¡è¿­ä»£åšå‡†å¤‡
            self.optimizer.zero_grad()

        # åœ¨å¤šè®¾å¤‡è®­ç»ƒä¸­æ”¶é›†æ‰€æœ‰è®¾å¤‡ä¸Šçš„é¢„æµ‹å€¼ã€æ ‡ç­¾å’ŒæŸå¤±
        # gatherå‡½æ•°ä¼šæ”¶é›†æ‰€æœ‰GPU/TPUä¸Šçš„æ•°æ®
        all_preds = self.accelerator.gather(preds)
        all_labels = self.accelerator.gather(labels)
        all_loss = self.accelerator.gather(loss).sum()

        # æ„é€ å½“å‰æ­¥éª¤çš„æŸå¤±å­—å…¸ï¼Œé”®ååŒ…å«é˜¶æ®µä¿¡æ¯ï¼ˆtrain_lossæˆ–val_lossï¼‰
        # stageè¿”å›å½“å‰çš„é˜¶æ®µï¼ˆtrainæˆ–valï¼‰ï¼Œç”¨äºåŒºåˆ†è®­ç»ƒå’ŒéªŒè¯æŸå¤±
        step_losses = {self.stage+"_loss":all_loss.item()}

        # è®¡ç®—å¹¶æ›´æ–°è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœæä¾›äº†æŒ‡æ ‡å­—å…¸ï¼‰
        if self.metrics_dict:
            # ç¡®ä¿é¢„æµ‹å€¼å’Œæ ‡ç­¾çš„å½¢çŠ¶ä¸€è‡´ï¼Œå¤„ç†ç»´åº¦é—®é¢˜
            # å¦‚æœé¢„æµ‹å€¼å’Œæ ‡ç­¾æ˜¯å¤šç»´çš„ï¼Œå»æ‰æœ€åä¸€ä¸ªç»´åº¦
            preds_fixed = all_preds.squeeze(-1) if all_preds.dim() > 1 else all_preds
            labels_fixed = all_labels.squeeze(-1) if all_labels.dim() > 1 else all_labels

            # æ›´æ–°æ¯ä¸ªæŒ‡æ ‡çš„ç´¯ç§¯çŠ¶æ€ï¼ˆç”¨äºepochç»“æŸæ—¶çš„æœ€ç»ˆè®¡ç®—ï¼‰
            for name, metric_fn in self.metrics_dict.items():
                metric_fn.update(preds_fixed, labels_fixed)

            # è®¡ç®—å½“å‰æ­¥éª¤çš„æŒ‡æ ‡å€¼ï¼Œæ„é€ æŒ‡æ ‡å­—å…¸
            # xx.item()å°†å¼ é‡è½¬æ¢ä¸ºPythonæ ‡é‡,æ–¹ä¾¿è®°å½•å’Œæ˜¾ç¤ºï¼Œå¦‚æœä¸è½¬æ¢å¯èƒ½ä¼šå¯¼è‡´æ˜¾ç¤ºé—®é¢˜
            #è®¡ç®—æ—¶ä¸ç”¨ .item() - ä¿æŒæ¢¯åº¦å’Œå¼ é‡è¿ç®—èƒ½åŠ›
            #æ˜¾ç¤ºæ—¶ä½¿ç”¨ .item() - æ›´æ¸…æ™°çš„æ•°å€¼æ˜¾ç¤º
            #å­˜å‚¨æ—¶ä½¿ç”¨ .item() - èŠ‚çœå†…å­˜å’Œæ”¯æŒåºåˆ—åŒ–
            step_metrics = {self.stage+"_"+name:metric_fn(preds_fixed, labels_fixed).item()
                        for name, metric_fn in self.metrics_dict.items()}
        else:
            # å¦‚æœæ²¡æœ‰æä¾›æŒ‡æ ‡å­—å…¸ï¼Œåˆ™è¿”å›ç©ºå­—å…¸
            step_metrics = {}

        # åœ¨è®­ç»ƒé˜¶æ®µè®°å½•å½“å‰å­¦ä¹ ç‡
        if self.stage=="train":
            if self.optimizer is not None:
                # ä»ä¼˜åŒ–å™¨çš„çŠ¶æ€å­—å…¸ä¸­è·å–å½“å‰å­¦ä¹ ç‡
                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']
            else:
                # å¦‚æœæ²¡æœ‰ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡è®¾ä¸º0
                step_metrics['lr'] = 0.0
        # è¿”å›å½“å‰æ­¥éª¤çš„æŸå¤±å’ŒæŒ‡æ ‡
        return step_losses,step_metrics


# å®šä¹‰EpochRunnerç±»ï¼Œè´Ÿè´£å¤„ç†å®Œæ•´epochçš„è®­ç»ƒæˆ–éªŒè¯è¿‡ç¨‹
class EpochRunner:
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥æ”¶steprunnerå®ä¾‹å’Œé™é»˜æ¨¡å¼æ ‡å¿—
    def __init__(self,steprunner,quiet=False):
        # ä¿å­˜steprunnerå®ä¾‹
        self.steprunner = steprunner
        # è·å–å½“å‰é˜¶æ®µï¼ˆè®­ç»ƒæˆ–éªŒè¯ï¼‰
        self.stage = steprunner.stage
        # æ ¹æ®é˜¶æ®µè®¾ç½®æ¨¡å‹æ¨¡å¼ï¼šè®­ç»ƒæ¨¡å¼æˆ–è¯„ä¼°æ¨¡å¼
        self.steprunner.net.train() if self.stage=="train" else self.steprunner.net.eval()
        # ä¿å­˜acceleratorå®ä¾‹
        self.accelerator = self.steprunner.accelerator
        # ä¿å­˜é™é»˜æ¨¡å¼æ ‡å¿—ï¼Œæ§åˆ¶æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        self.quiet = quiet

    # å®šä¹‰__call__æ–¹æ³•ï¼Œå¤„ç†æ•´ä¸ªæ•°æ®åŠ è½½å™¨çš„æ‰€æœ‰batch
    def __call__(self,dataloader):
        # åˆ›å»ºè¿›åº¦æ¡ï¼Œæ˜¾ç¤ºè®­ç»ƒ/éªŒè¯è¿›åº¦
        loop = tqdm(enumerate(dataloader,start=1),  # ä»1å¼€å§‹æšä¸¾
                    total =len(dataloader),          # æ€»æ­¥æ•°
                    file=sys.stdout,                 # è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º
                    disable=not self.accelerator.is_local_main_process or self.quiet,  # ä»…ä¸»è¿›ç¨‹æ˜¾ç¤ºæˆ–æ ¹æ®quietå‚æ•°
                    ncols = 100                      # è¿›åº¦æ¡å®½åº¦
                   )
        # åˆå§‹åŒ–epochçº§åˆ«çš„æŸå¤±ç´¯ç§¯å­—å…¸
        epoch_losses = {}
        # éå†æ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªbatch
        for step, batch in loop:
            # æ ¹æ®é˜¶æ®µå†³å®šæ˜¯å¦ä½¿ç”¨æ¢¯åº¦è®¡ç®—
            if self.stage=="train":
                # è®­ç»ƒé˜¶æ®µéœ€è¦è®¡ç®—æ¢¯åº¦
                step_losses,step_metrics = self.steprunner(batch)
            else:
                # éªŒè¯é˜¶æ®µä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œä½¿ç”¨torch.no_grad()æé«˜æ•ˆç‡
                with torch.no_grad():
                    step_losses,step_metrics = self.steprunner(batch)

            # åˆå¹¶å½“å‰æ­¥éª¤çš„æŸå¤±å’ŒæŒ‡æ ‡åˆ°ä¸€ä¸ªå­—å…¸ä¸­
            step_log = dict(step_losses,**step_metrics)
            # å°†batchçš„æŸå¤±å€¼ç´¯ç§¯åˆ°epoch_lossesä¸­ï¼Œkå’Œvåˆ†åˆ«æ˜¯é”®å’Œå€¼
            for k,v in step_losses.items():
                # xx.get(k,0.0) - å¦‚æœkä¸å­˜åœ¨åˆ™è¿”å›0.0
                epoch_losses[k] = epoch_losses.get(k,0.0)+v

            # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºä¿¡æ¯
            if step!=len(dataloader):
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ­¥ï¼Œæ˜¾ç¤ºå½“å‰æ­¥éª¤çš„æŒ‡æ ‡ã€‚loopä½œç”¨æ˜¯æ›´æ–°è¿›åº¦æ¡
                loop.set_postfix(**step_log)
            else:
                # å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œè®¡ç®—epochçº§åˆ«çš„æŒ‡æ ‡
                epoch_metrics = step_metrics
                
                # è®¡ç®—epochç»“æŸæ—¶çš„ç´¯ç§¯æŒ‡æ ‡ï¼Œæ·»åŠ å®‰å…¨æ£€æŸ¥é¿å…è¿è¡Œæ—¶é”™è¯¯
                if self.steprunner.metrics_dict:
                    try:
                        # è°ƒç”¨æ¯ä¸ªæŒ‡æ ‡çš„computeæ–¹æ³•è·å–epochçº§åˆ«çš„ç»“æœ
                        # stageåŒ…æ‹¬trainæˆ–valï¼Œnameæ˜¯metric_dictä¸­çš„æŒ‡æ ‡åç§°ï¼ˆåº”è¯¥åªæœ‰maeå’Œmapeï¼‰
                        epoch_metrics.update({self.stage+"_"+name:metric_fn.compute().item()
                                         for name,metric_fn in self.steprunner.metrics_dict.items()})
                    except RuntimeError as e:
                        # å¦‚æœè®¡ç®—æŒ‡æ ‡æ—¶å‡ºç°å½¢çŠ¶é—®é¢˜ï¼Œæ‰“å°è­¦å‘Šå¹¶è·³è¿‡
                        print(f"Warning: Could not compute epoch metrics: {e}")
                        pass
                
                # è®¡ç®—epochçº§åˆ«çš„å¹³å‡æŸå¤±ï¼Œkæ˜¯æŸå¤±åç§°ï¼Œvæ˜¯ç´¯ç§¯æŸå¤±å€¼ï¼ˆv/step: è¯¥æŸå¤±çš„epochå¹³å‡å€¼ï¼‰
                # è¿™é‡Œçš„stepæ˜¯å½“å‰epochçš„æ€»batchæ•°
                epoch_losses = {k:v/step for k,v in epoch_losses.items()}
                # åˆå¹¶æŸå¤±å’ŒæŒ‡æ ‡
                epoch_log = dict(epoch_losses,**epoch_metrics)
                # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºæœ€ç»ˆçš„epochä¿¡æ¯
                loop.set_postfix(**epoch_log)
                
                # é‡ç½®æ‰€æœ‰æŒ‡æ ‡çš„çŠ¶æ€ï¼Œä¸ºä¸‹ä¸€ä¸ªepochåšå‡†å¤‡
                if self.steprunner.metrics_dict:
                    for name,metric_fn in self.steprunner.metrics_dict.items():
                        metric_fn.reset()
        # è¿”å›epochçº§åˆ«çš„æ—¥å¿—ä¿¡æ¯
        return epoch_log


# å®šä¹‰KerasModelç±»ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¿ç…§Kerasé£æ ¼çš„PyTorchæ¨¡å‹åŒ…è£…å™¨
class KerasModel(torch.nn.Module):
    
    # ç±»å±æ€§ï¼šæŒ‡å®šä½¿ç”¨çš„StepRunnerå’ŒEpochRunnerç±»
    StepRunner,EpochRunner = StepRunner,EpochRunner
    
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®æ¨¡å‹çš„å„ä¸ªç»„ä»¶
    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        super().__init__()
        # ä¿å­˜ç½‘ç»œæ¨¡å‹ã€æŸå¤±å‡½æ•°å’ŒæŒ‡æ ‡å­—å…¸ï¼ˆè½¬æ¢ä¸ºModuleDictä»¥ä¾¿GPUç§»åŠ¨ï¼‰
        self.net,self.loss_fn,self.metrics_dict = net, loss_fn, torch.nn.ModuleDict(metrics_dict) 
        # è®¾ç½®ä¼˜åŒ–å™¨ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤çš„Adamä¼˜åŒ–å™¨
        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(
            self.net.parameters(), lr=1e-3)
        # ä¿å­˜å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.lr_scheduler = lr_scheduler
        # æ ‡è®°æ˜¯å¦ä»é›¶å¼€å§‹è®­ç»ƒ
        self.from_scratch = True

    # åŠ è½½æ£€æŸ¥ç‚¹çš„æ–¹æ³•
    def load_ckpt(self, ckpt_path='checkpoint.pt'):
        # åŠ è½½ä¿å­˜çš„æ¨¡å‹æƒé‡ï¼ˆweights_only=Falseå…è®¸åŠ è½½å®Œæ•´æ¨¡å‹ï¼‰
        self.net= torch.load(ckpt_path, weights_only=False)  #ä¿®æ”¹è¿‡ï¼Œä¹‹å‰self.net= torch.load(ckpt_path)
        # æ ‡è®°ä¸æ˜¯ä»é›¶å¼€å§‹è®­ç»ƒ
        self.from_scratch = False

    # å‰å‘ä¼ æ’­æ–¹æ³•
    def forward(self, x):
        return self.net.forward(x)
    
    # è®­ç»ƒæ–¹æ³•ï¼Œè¿™æ˜¯æ¨¡å‹è®­ç»ƒçš„ä¸»è¦å…¥å£ç‚¹
    def fit(self, train_data, val_data=None, epochs=10,ckpt_path='checkpoint.pt',
            patience=5, monitor="val_loss", mode="min",
            mixed_precision='no',callbacks = None, plot = True, quiet = True):
        
        # å°†æ‰€æœ‰å±€éƒ¨å˜é‡ä¿å­˜åˆ°å®ä¾‹å­—å…¸ä¸­ï¼Œæ–¹ä¾¿åç»­è®¿é—®
        self.__dict__.update(locals())
        # åˆå§‹åŒ–Acceleratorï¼Œè®¾ç½®æ··åˆç²¾åº¦è®­ç»ƒ
        self.accelerator = Accelerator(mixed_precision=mixed_precision)
        # è·å–è®¾å¤‡ä¿¡æ¯
        device = str(self.accelerator.device)
        # æ ¹æ®è®¾å¤‡ç±»å‹é€‰æ‹©æ˜¾ç¤ºå›¾æ ‡
        device_type = 'ğŸŒ'  if 'cpu' in device else 'âš¡ï¸'
        # æ‰“å°è®¾å¤‡ä¿¡æ¯
        self.accelerator.print(
            colorful("<<<<<< "+device_type +" "+ device +" is used >>>>>>"))
    
        # ä½¿ç”¨acceleratorå‡†å¤‡æ‰€æœ‰ç»„ä»¶ï¼Œè¿™ä¼šè‡ªåŠ¨å¤„ç†å¤šè®¾å¤‡åˆ†å¸ƒ
        self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler= self.accelerator.prepare(
            self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler)
        
        # å‡†å¤‡æ•°æ®åŠ è½½å™¨
        train_dataloader,val_dataloader = self.accelerator.prepare(train_data,val_data)
        
        # åˆå§‹åŒ–è®­ç»ƒå†å²è®°å½•å­—å…¸
        self.history = {}
        # è®¾ç½®å›è°ƒå‡½æ•°åˆ—è¡¨
        callbacks = callbacks if callbacks is not None else []
        
        # å¦‚æœéœ€è¦ç»˜å›¾ï¼Œæ·»åŠ å¯è§†åŒ–è¿›åº¦å›è°ƒ
        if plot==True: 
            from utils.keras_callbacks import VisProgress
            callbacks.append(VisProgress(self))

        # å‡†å¤‡å›è°ƒå‡½æ•°
        self.callbacks = self.accelerator.prepare(callbacks)
        
        # åœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œè®­ç»ƒå¼€å§‹å›è°ƒ
        if self.accelerator.is_local_main_process:
            for callback_obj in self.callbacks:
                callback_obj.on_fit_start(model = self)
        
        # ç¡®å®šå¼€å§‹epochï¼šä»é›¶å¼€å§‹æˆ–ä»æ£€æŸ¥ç‚¹ç»§ç»­
        start_epoch = 1 if self.from_scratch else 0
        # ä¸»è®­ç»ƒå¾ªç¯
        for epoch in range(start_epoch,epochs+1):
            # è®°å½•epochå¼€å§‹æ—¶é—´
            import time
            start_time = time.time()
            
            # æ ¹æ®quietå‚æ•°ç¡®å®šæ˜¯å¦é™é»˜è¿è¡Œ
            should_quiet = False if quiet==False else (quiet==True or epoch>quiet)
            
            # å¦‚æœä¸æ˜¯é™é»˜æ¨¡å¼ï¼Œæ‰“å°epochä¿¡æ¯
            if not should_quiet:
                nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self.accelerator.print("\n"+"=========="*8 + "%s"%nowtime)
                self.accelerator.print("Epoch {0} / {1}".format(epoch, epochs)+"\n")

            # 1. è®­ç»ƒé˜¶æ®µ -------------------------------------------------  
            # åˆ›å»ºè®­ç»ƒæ­¥éª¤è¿è¡Œå™¨
            train_step_runner = self.StepRunner(
                    net = self.net,
                    loss_fn = self.loss_fn,
                    accelerator = self.accelerator,
                    stage="train",
                    metrics_dict=deepcopy(self.metrics_dict),  # æ·±æ‹·è´é¿å…çŠ¶æ€æ±¡æŸ“
                    optimizer = self.optimizer if epoch>0 else None,    # epoch 0æ—¶ä¸æ›´æ–°å‚æ•°
                    lr_scheduler = self.lr_scheduler if epoch>0 else None
            )

            # åˆ›å»ºè®­ç»ƒepochè¿è¡Œå™¨
            train_epoch_runner = self.EpochRunner(train_step_runner,should_quiet)
          
            # åˆå§‹åŒ–è®­ç»ƒæŒ‡æ ‡å¹¶æ‰§è¡Œè®­ç»ƒ
            train_metrics = {'epoch':epoch}
            train_metrics.update(train_epoch_runner(train_dataloader)) 

            # å°†è®­ç»ƒæŒ‡æ ‡æ·»åŠ åˆ°å†å²è®°å½•ä¸­
            for name, metric in train_metrics.items(): 
                self.history[name] = self.history.get(name, []) + [metric]

            # å¦‚æœå½“å‰è¿›ç¨‹æ˜¯ä¸»è¿›ç¨‹ï¼Œæ‰§è¡Œè®­ç»ƒepochç»“æŸå›è°ƒ
            # å›è°ƒä½œç”¨æ˜¯åœ¨æ¯ä¸ªepochç»“æŸæ—¶æ‰§è¡Œç‰¹å®šæ“ä½œï¼Œå¦‚æ—¥å¿—è®°å½•ã€æ¨¡å‹ä¿å­˜ç­‰
            if self.accelerator.is_local_main_process:
                for callback_obj in self.callbacks:
                    callback_obj.on_train_epoch_end(model = self)

            # 2. éªŒè¯é˜¶æ®µ -------------------------------------------------
            if val_dataloader:
                # åˆ›å»ºéªŒè¯æ­¥éª¤è¿è¡Œå™¨
                val_step_runner = self.StepRunner(
                    net = self.net,
                    loss_fn = self.loss_fn,
                    accelerator = self.accelerator,
                    stage="val",
                    metrics_dict= deepcopy(self.metrics_dict)  # éªŒè¯é˜¶æ®µä¸éœ€è¦ä¼˜åŒ–å™¨
                )
                # åˆ›å»ºéªŒè¯epochè¿è¡Œå™¨
                val_epoch_runner = self.EpochRunner(val_step_runner,should_quiet)
                # åœ¨no_gradç¯å¢ƒä¸‹æ‰§è¡ŒéªŒè¯ï¼Œwith torch.no_grad()ç¡®ä¿ä¸è®¡ç®—æ¢¯åº¦,ç›®çš„æ˜¯æé«˜éªŒè¯é€Ÿåº¦å’ŒèŠ‚çœå†…å­˜
                # è¿™åœ¨éªŒè¯é˜¶æ®µæ˜¯å¸¸è§çš„åšæ³•ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦æ›´æ–°æ¨¡å‹
                # åªéœ€è¦è®¡ç®—æŸå¤±å’Œè¯„ä¼°æŒ‡æ ‡å³å¯
                with torch.no_grad():
                    val_metrics = val_epoch_runner(val_dataloader)
                    # æ ¹æ®è°ƒåº¦å™¨ç±»å‹è¿›è¡Œå­¦ä¹ ç‡è°ƒæ•´
                    if self.lr_scheduler.scheduler_type == "ReduceLROnPlateau":
                        # ReduceLROnPlateauéœ€è¦ç›‘æ§æŒ‡æ ‡
                        self.lr_scheduler.step(
                            metrics=val_metrics['val_mae'])
                    else:
                        # å…¶ä»–è°ƒåº¦å™¨æŒ‰epochè°ƒæ•´
                        self.lr_scheduler.step()
                # å°†éªŒè¯æŒ‡æ ‡ä¾æ¬¡æ·»åŠ åˆ°å†å²è®°å½•ä¸­
                for name, metric in val_metrics.items(): 
                    self.history[name] = self.history.get(name, []) + [metric]

            # 3. æ—©åœæœºåˆ¶ -------------------------------------------------
            # ç­‰å¾…æ‰€æœ‰è®¾å¤‡åŒæ­¥
            self.accelerator.wait_for_everyone()
            # è·å–ç›‘æ§æŒ‡æ ‡çš„å†å²å€¼
            arr_scores = self.history[monitor]
            # è®°å½•å½“å‰æœ€ä½³æŒ‡æ ‡å€¼
            self.history['best_val_mae'] = self.history.get('best_val_mae', []) + [ np.min(arr_scores) if mode=="min" else np.max(arr_scores)]  

            # æ‰¾åˆ°æœ€ä½³åˆ†æ•°çš„ç´¢å¼•ä½ç½®
            best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)

            # å¦‚æœå½“å‰epochè·å¾—äº†æœ€ä½³åˆ†æ•°ï¼Œä¿å­˜æ¨¡å‹
            if best_score_idx==len(arr_scores)-1:
                self.accelerator.save(self.net,ckpt_path)
                if not should_quiet:
                    self.accelerator.print(colorful("<<<<<< reach best {0} : {1} >>>>>>".format(
                        monitor,arr_scores[best_score_idx])))

            # è®°å½•epochç»“æŸæ—¶é—´
            end_time = time.time()
            self.history['time'] = self.history.get('time', []) + [end_time-start_time]
          
            # æ£€æŸ¥æ˜¯å¦è§¦å‘æ—©åœæ¡ä»¶
            if len(arr_scores)-best_score_idx>patience:
                self.accelerator.print(colorful(
                    "<<<<<< {} without improvement in {} epoch,""early stopping >>>>>>"
                ).format(monitor,patience))
                break; 
            
            # æ‰§è¡ŒéªŒè¯epochç»“æŸå›è°ƒ
            if self.accelerator.is_local_main_process:
                for callback_obj in self.callbacks:
                    callback_obj.on_validation_epoch_end(model = self)
        
        # è®­ç»ƒç»“æŸåçš„å¤„ç†
        if self.accelerator.is_local_main_process:   
            # å°†å†å²è®°å½•è½¬æ¢ä¸ºDataFrame
            dfhistory = pd.DataFrame(self.history)
            self.accelerator.print(dfhistory)
            
            # æ‰§è¡Œè®­ç»ƒç»“æŸå›è°ƒ
            for callback_obj in self.callbacks:
                callback_obj.on_fit_end(model = self)
        
            # è§£åŒ…æ¨¡å‹å¹¶åŠ è½½æœ€ä½³æƒé‡
            self.net = self.accelerator.unwrap_model(self.net)
            self.net = torch.load(ckpt_path)
            return dfhistory
    
    # æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œç”¨äºåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
    @torch.no_grad()  # è£…é¥°å™¨ï¼Œç¡®ä¿ä¸‹é¢çš„ä»£ç éƒ½ä¸è®¡ç®—æ¢¯åº¦
    def evaluate(self, val_data):
        # å¦‚æœå‰é¢æ²¡æœ‰@torch.no_grad()ï¼Œåˆ™è¿™é‡Œéœ€è¦åŠ å…¥ä¸€ä¸ªwith torch.no_grad():
        # åˆ›å»ºæ–°çš„acceleratorå®ä¾‹
        accelerator = Accelerator()
        # å‡†å¤‡æ¨¡å‹ç»„ä»¶
        self.net,self.loss_fn,self.metrics_dict = accelerator.prepare(self.net,self.loss_fn,self.metrics_dict)
        # å‡†å¤‡éªŒè¯æ•°æ®
        val_data = accelerator.prepare(val_data)
        # åˆ›å»ºéªŒè¯æ­¥éª¤è¿è¡Œå™¨
        val_step_runner = self.StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = accelerator)
        # åˆ›å»ºéªŒè¯epochè¿è¡Œå™¨
        val_epoch_runner = self.EpochRunner(val_step_runner)
        # æ‰§è¡ŒéªŒè¯å¹¶è¿”å›ç»“æœ
        val_metrics = val_epoch_runner(val_data)
        return val_metrics
    
    # æ¨¡å‹é¢„æµ‹æ–¹æ³•ï¼Œç”¨äºåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹
    @torch.no_grad()  # è£…é¥°å™¨ï¼Œç¡®ä¿ä¸è®¡ç®—æ¢¯åº¦
    def predict(self, test_data,ckpt_path, test_out_path='test_out.csv'):
        # ä¿å­˜æ£€æŸ¥ç‚¹è·¯å¾„
        self.ckpt_path = ckpt_path
        # åŠ è½½æ¨¡å‹æƒé‡
        self.load_ckpt(self.ckpt_path)
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.net.eval()
        # åˆå§‹åŒ–ç»“æœå­˜å‚¨åˆ—è¡¨
        targets = []   # çœŸå®æ ‡ç­¾
        outputs = []   # æ¨¡å‹é¢„æµ‹å€¼
        id = []        # æ ·æœ¬ID
        
        # éå†æµ‹è¯•æ•°æ®
        for data in test_data:
            with torch.no_grad():
                # å°†æ•°æ®ç§»åŠ¨åˆ°GPU
                data = data.to(torch.device('cuda'))
                # æ”¶é›†çœŸå®æ ‡ç­¾
                targets.append(data.y.cpu().numpy().tolist())
                # è¿›è¡Œé¢„æµ‹
                output = self.net(data)
                # æ”¶é›†é¢„æµ‹ç»“æœ
                outputs.append(output.cpu().numpy().tolist())
                # æ”¶é›†æ ·æœ¬ID
                id += data.structure_id
        
        # å°†åµŒå¥—åˆ—è¡¨å±•å¹³
        targets = sum(targets, [])
        outputs = sum(outputs, [])
        id = sum(sum(id, []),[])
        
        # å¯¼å…¥CSVå†™å…¥æ¨¡å—
        import csv
        # ç»„åˆæ•°æ®è¡Œ
        rows = zip(
            id,
            targets,
            outputs
        )
        # å†™å…¥CSVæ–‡ä»¶
        with open(test_out_path, "w") as csv_file:
            writer = csv.writer(csv_file, delimiter=",")
            for row in rows:
                writer.writerow(row)

    # cubicæ–¹æ³•ï¼Œä¸predictæ–¹æ³•ç›¸åŒï¼Œä»…é»˜è®¤è¾“å‡ºæ–‡ä»¶åæœ‰åŒºåˆ«ï¼Œå¯èƒ½ç”¨äºç‰¹å®šæ•°æ®é›†
    @torch.no_grad()  # è£…é¥°å™¨ï¼Œç¡®ä¿ä¸è®¡ç®—æ¢¯åº¦
    def cubic(self, test_data,ckpt_path, test_out_path='cubic_out.csv'):
        # ä¿å­˜æ£€æŸ¥ç‚¹è·¯å¾„
        self.ckpt_path = ckpt_path
        # åŠ è½½æ¨¡å‹æƒé‡
        self.load_ckpt(self.ckpt_path)
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.net.eval()
        # åˆå§‹åŒ–ç»“æœå­˜å‚¨åˆ—è¡¨
        targets = []   # çœŸå®æ ‡ç­¾
        outputs = []   # æ¨¡å‹é¢„æµ‹å€¼
        id = []        # æ ·æœ¬ID
        
        # éå†æµ‹è¯•æ•°æ®
        for data in test_data:
            with torch.no_grad():
                # å°†æ•°æ®ç§»åŠ¨åˆ°GPU
                data = data.to(torch.device('cuda'))
                # æ”¶é›†çœŸå®æ ‡ç­¾
                targets.append(data.y.cpu().numpy().tolist())
                # è¿›è¡Œé¢„æµ‹
                output = self.net(data)
                # æ”¶é›†é¢„æµ‹ç»“æœ
                outputs.append(output.cpu().numpy().tolist())
                # æ”¶é›†æ ·æœ¬ID
                id += data.structure_id
        
        # å°†åµŒå¥—åˆ—è¡¨å±•å¹³
        targets = sum(targets, [])
        outputs = sum(outputs, [])
        id = sum(sum(id, []),[])
        
        # å¯¼å…¥CSVå†™å…¥æ¨¡å—
        import csv
        # ç»„åˆæ•°æ®è¡Œ
        rows = zip(
            id,
            targets,
            outputs
        )
        # å†™å…¥CSVæ–‡ä»¶
        with open(test_out_path, "w") as csv_file:
            writer = csv.writer(csv_file, delimiter=",")
            for row in rows:
                writer.writerow(row)

    # åˆ†ææ–¹æ³•ï¼Œä½¿ç”¨t-SNEå¯¹è®­ç»ƒå¥½çš„æ¨¡å‹ç‰¹å¾è¿›è¡Œå¯è§†åŒ–åˆ†æ
    @torch.no_grad()  # è£…é¥°å™¨ï¼Œç¡®ä¿ä¸è®¡ç®—æ¢¯åº¦
    def analysis(self, net_name,test_data, ckpt_path, tsne_args,tsne_file_path="tsne_output.png"):
        '''
        ä»è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­è·å–å›¾ç‰¹å¾å¹¶ä½¿ç”¨t-SNEè¿›è¡Œåˆ†æ
        '''
        # å¯¼å…¥å¿…è¦çš„åˆ†æåº“
        from sklearn.decomposition import PCA      # ä¸»æˆåˆ†åˆ†æ
        from sklearn.manifold import TSNE         # t-SNEé™ç»´
        import matplotlib.pyplot as plt           # ç»˜å›¾åº“
        
        # åˆå§‹åŒ–è¾“å…¥ç‰¹å¾å­˜å‚¨åˆ—è¡¨
        inputs = []
        # å®šä¹‰é’©å­å‡½æ•°ï¼Œç”¨äºæ•è·ä¸­é—´å±‚çš„è¾“å…¥
        def hook(module, input, output):
            inputs.append(input)

        # ä¿å­˜æ£€æŸ¥ç‚¹è·¯å¾„å¹¶åŠ è½½æ¨¡å‹
        self.ckpt_path = ckpt_path
        self.load_ckpt(self.ckpt_path)
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.net.eval()
        
        # æ ¹æ®ç½‘ç»œåç§°æ³¨å†Œå‰å‘é’©å­ï¼Œæ•è·ç¬¬ä¸€ä¸ªçº¿æ€§å±‚çš„è¾“å…¥
        if net_name in [ "ALIGNN","CLIGNN", "GCPNet"]:
            # å¯¹äºè¿™äº›ç½‘ç»œï¼Œé’©å­æ³¨å†Œåˆ°fcå±‚
            # fcå±‚çš„è¾“å…¥æ˜¯æ•´ä¸ªç½‘ç»œæå–çš„æœ€ç»ˆç‰¹å¾
            self.net.fc.register_forward_hook(hook)
        else:
            # å¯¹äºå…¶ä»–ç½‘ç»œï¼Œé’©å­æ³¨å†Œåˆ°post_lin_listçš„ç¬¬ä¸€å±‚
            # post_lin_list[0]çš„è¾“å…¥æ˜¯ç‰¹å¾æå–å™¨çš„è¾“å‡º
            self.net.post_lin_list[0].register_forward_hook(hook)

        # åˆå§‹åŒ–ç›®æ ‡å€¼å­˜å‚¨åˆ—è¡¨ï¼ˆä»…é€‚ç”¨äºå•ç´¢å¼•ç›®æ ‡ï¼‰
        targets = []
        # éå†æµ‹è¯•æ•°æ®
        for data in test_data:
            with torch.no_grad():
                # å°†æ•°æ®ç§»åŠ¨åˆ°GPU
                data = data.to(torch.device('cuda'))
                # æ”¶é›†ç›®æ ‡å€¼
                targets.append(data.y.cpu().numpy().tolist())
                # è¿›è¡Œå‰å‘ä¼ æ’­ï¼ˆè§¦å‘é’©å­å‡½æ•°ï¼‰
                _ = self.net(data)

        # å¤„ç†æ”¶é›†åˆ°çš„æ•°æ®
        targets = sum(targets, [])                    # å±•å¹³ç›®æ ‡å€¼åˆ—è¡¨
        inputs = [i for sub in inputs for i in sub]   # å±•å¹³è¾“å…¥ç‰¹å¾åˆ—è¡¨
        inputs = torch.cat(inputs)                    # è¿æ¥æ‰€æœ‰è¾“å…¥å¼ é‡
        inputs = inputs.cpu().numpy()                 # è½¬æ¢ä¸ºnumpyæ•°ç»„
        
        # æ‰“å°æ•°æ®ä¿¡æ¯
        print("Number of samples: ", inputs.shape[0])
        print("Number of features: ", inputs.shape[1])

        # å¼€å§‹t-SNEåˆ†æ
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°åˆ›å»ºt-SNEå¯¹è±¡
        tsne = TSNE(**tsne_args)
        # æ‰§è¡Œt-SNEé™ç»´
        tsne_out = tsne.fit_transform(inputs)

        # åˆ›å»ºæ•£ç‚¹å›¾è¿›è¡Œå¯è§†åŒ–
        fig, ax = plt.subplots()
        # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œé¢œè‰²æ˜ å°„åˆ°ç›®æ ‡å€¼
        main = plt.scatter(tsne_out[:, 1], tsne_out[:, 0], c=targets, s=3,cmap='coolwarm')
        # ç§»é™¤åæ ‡è½´æ ‡ç­¾å’Œåˆ»åº¦
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_xticks([])
        ax.set_yticks([])
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(main, ax=ax)
        # è®¡ç®—æ ‡å‡†å·®ç”¨äºè®¾ç½®é¢œè‰²èŒƒå›´
        stdev = np.std(targets)
        # è®¾ç½®é¢œè‰²æ¡çš„èŒƒå›´ä¸ºå‡å€¼Â±2å€æ ‡å‡†å·®
        cbar.mappable.set_clim(
            np.mean(targets) - 2 * np.std(targets), np.mean(targets) + 2 * np.std(targets)
        )
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(tsne_file_path, format="png", dpi=600)
        # æ˜¾ç¤ºå›¾ç‰‡
        plt.show()

    # è¿”å›æ¨¡å‹æ€»å‚æ•°æ•°é‡çš„æ–¹æ³•
    def total_params(self):
        return self.net.total_params()


# å­¦ä¹ ç‡è°ƒåº¦å™¨åŒ…è£…ç±»ï¼Œå°è£…PyTorchçš„å­¦ä¹ ç‡è°ƒåº¦å™¨
class LRScheduler:
    """PyTorchå­¦ä¹ ç‡è°ƒåº¦å™¨çš„åŒ…è£…ç±»"""

    # åˆå§‹åŒ–æ–¹æ³•
    def __init__(self, optimizer, scheduler_type, model_parameters):
        # ä¿å­˜ä¼˜åŒ–å™¨
        self.optimizer = optimizer
        # ä¿å­˜è°ƒåº¦å™¨ç±»å‹
        self.scheduler_type = scheduler_type

        # åŠ¨æ€è·å–å¹¶åˆ›å»ºå¯¹åº”çš„è°ƒåº¦å™¨å®ä¾‹
        self.scheduler = getattr(torch.optim.lr_scheduler, self.scheduler_type)(
            optimizer, **model_parameters
        )

        # ä¿å­˜å½“å‰å­¦ä¹ ç‡
        self.lr = self.optimizer.param_groups[0]["lr"]

    # ç±»æ–¹æ³•ï¼šä»é…ç½®åˆ›å»ºLRSchedulerå®ä¾‹
    @classmethod        #æœ‰è£…é¥°å™¨åˆ™ä¸‹é¢çš„ç¬¬ä¸€ä¸ªå‚æ•°clsæ˜¯LRSchedulerç±»
    def from_config(cls, optimizer, optim_config):
        # ä»é…ç½®ä¸­æå–è°ƒåº¦å™¨ç±»å‹
        scheduler_type = optim_config["scheduler_type"]
        # ä»é…ç½®ä¸­æå–è°ƒåº¦å™¨å‚æ•°
        scheduler_args = optim_config["scheduler_args"]
        # å¯¹åº”initä¸­çš„å‚æ•°ï¼Œåˆ†åˆ«æ˜¯è¦è°ƒåº¦çš„ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ç±»å‹å’Œè°ƒåº¦å™¨å‚æ•°
        # åˆ›å»ºå¹¶è¿”å›LRSchedulerå®ä¾‹
        return cls(optimizer, scheduler_type, **scheduler_args)

    # æ‰§è¡Œå­¦ä¹ ç‡è°ƒåº¦æ­¥éª¤
    def step(self, metrics=None, epoch=None):
        # å¦‚æœæ˜¯ç©ºè°ƒåº¦å™¨ï¼Œç›´æ¥è¿”å›
        if self.scheduler_type == "Null":
            return
        # å¦‚æœæ˜¯ReduceLROnPlateauç±»å‹ï¼Œéœ€è¦ä¼ å…¥ç›‘æ§æŒ‡æ ‡
        if self.scheduler_type == "ReduceLROnPlateau":
            if metrics is None:
                # å¦‚æœæ²¡æœ‰æä¾›æŒ‡æ ‡ï¼ŒæŠ›å‡ºå¼‚å¸¸
                raise Exception("Validation set required for ReduceLROnPlateau.")
            # ä½¿ç”¨æŒ‡æ ‡è¿›è¡Œè°ƒåº¦
            self.scheduler.step(metrics)
        else:
            # å…¶ä»–è°ƒåº¦å™¨ç›´æ¥æ­¥è¿›
            self.scheduler.step()

        # æ›´æ–°å­¦ä¹ ç‡å±æ€§ä¸ºå½“å‰å­¦ä¹ ç‡
        self.update_lr()

    # æ›´æ–°å­¦ä¹ ç‡å±æ€§çš„æ–¹æ³•
    def update_lr(self):
        # éå†ä¼˜åŒ–å™¨çš„æ‰€æœ‰å‚æ•°ç»„ï¼Œæ›´æ–°å­¦ä¹ ç‡ï¼Œoptimizer.param_groupæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æ¯ä¸ªå‚æ•°ç»„çš„å­¦ä¹ ç‡ç­‰ä¿¡æ¯
        for param_group in self.optimizer.param_groups:
            self.lr = param_group["lr"]
